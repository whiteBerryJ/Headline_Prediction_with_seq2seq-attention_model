{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"news_headline.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RkOmdVRJPkSw","colab_type":"code","colab":{}},"source":["# !pip install konlpy\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"buAIQ_3JPjxm","colab_type":"code","colab":{}},"source":["from konlpy.tag import Hannanum, Kkma, Okt, Komoran\n","\n","komo = Komoran()\n","hannanum = Hannanum()\n","kkma = Kkma()\n","okt = Okt()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpOY2Ww6Qajm","colab_type":"code","colab":{}},"source":["import numpy as np\n","import re\n","import pandas as pd\n","import csv\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow import keras\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqMGzP16CLas","colab_type":"code","colab":{}},"source":["# 데이터 불러오기\n","news = pd.read_csv(\"/content/drive/My Drive//23035news_content_headline.csv\")\n","# news = news.append(dff, ignore_index=True)\n","news = news.loc[:, ['headline', 'content']]\n","\n","\n","# news.to_csv('23035news_content_headline.csv',encoding='utf-8-sig')\n","\n","news = news.dropna(axis=0)\n","# 불용어 제거\n","# 영어 대 소문자 제거\n","sw = '[a-zA-Z]'\n","news['content'] = news['content'].str.replace(sw, ' ')\n","news['headline'] = news['headline'].str.replace(sw, ' ')\n","\n","# 한글과 숫자를 제외한 특수문자 제거\n","news['content'] = news['content'].str.replace('[^\\w]', ' ' )\n","news['headline'] = news['headline'].str.replace('[^\\w]', ' ')\n","\n","# 기사 스탑워드 제거\n","news['content'] = news['content'].str.replace('기자의 다른기사 더보기', ' ')\n","\n","\n","\n","# 중복되는 헤드라인 행 제거\n","news = news.drop_duplicates(['headline'])\n","\n","\n","print(news)\n","print(news.content[1011:1020])\n","print(news.headline[1011:1020])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hr4ceMdWurit","colab_type":"code","colab":{}},"source":["# # 미리 토큰화된 것 부르기\n","\n","# encoder_input = []\n","# with open('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/18000encoder_input(kkma).txt', 'r') as f:\n","#     for line in f.readlines():\n","#         encoder_input.append(line.split())\n","# decoder_input = []\n","# with open('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/18000decoder_input(kkma).txt', 'r') as f:\n","#     for line in f.readlines():\n","#         decoder_input.append(line.split())\n","# decoder_output = []\n","# with open('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/18000decoder_output(kkma).txt', 'r') as f:\n","#     for line in f.readlines():\n","#         decoder_output.append(line.split())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOlfd1KH2id6","colab_type":"code","colab":{}},"source":["# 토큰화\n","# 형태소추출\n","\n","encoder_input, decoder_input, decoder_output = [], [], []\n","\n","i = 0\n","\n","for stc in news['content']:\n","    morphs = kkma.morphs(stc)\n","    if i% 100 == 0:\n","        print(i)\n","    i+=1\n","    encoder_input.append(morphs)\n","i = 0\n","for stc in news['headline']:\n","    morphs = kkma.morphs(stc)\n","    if i% 100 == 0:\n","        print(i)\n","    i+=1\n","    decoder_input.append([\"<start>\"]+ morphs)\n","i = 0\n","for stc in news['headline']:\n","    morphs = kkma.morphs(stc)\n","    if i% 100 == 0:\n","        print(i)\n","    i+=1\n","    decoder_output.append(morphs + [\"<end>\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1H3AJ5e-2-Hw","colab_type":"code","colab":{}},"source":["# 토큰화 된 것 부르기\n","with open('encoder_input.txt(kkma)', 'w') as f:\n","    for line in encoder_input:\n","        f.writelines(' '.join(line))\n","        f.write('\\n')\n","\n","with open('decoder_input.txt(kkma)', 'w') as f:\n","    for line in decoder_input:\n","        f.writelines(' '.join(line))\n","        f.write('\\n')\n","        \n","with open('decoder_output.txt(kkma)', 'w') as f:\n","    for line in decoder_output:\n","        f.writelines(' '.join(line))\n","        f.write('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CRHgCvdE93Nl","colab_type":"code","colab":{}},"source":["# with open('encoder_input.txt(komoran)', 'w') as f:\n","#     for line in encoder_input:\n","#         f.writelines(' '.join(line))\n","#         f.write('\\n')\n","# with open('decoder_input.txt(komoran)', 'w') as f:\n","#     for line in decoder_input:\n","#         f.writelines(' '.join(line))\n","#         f.write('\\n')\n","# with open('decoder_output.txt(komoran)', 'w') as f:\n","#     for line in decoder_output:\n","#         f.writelines(' '.join(line))\n","#         f.write('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eY-6BcqZWs42","colab_type":"code","colab":{}},"source":["print(encoder_input[:10])\n","print(decoder_input[:10])\n","print(decoder_output[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwbR8JxCek1s","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","\n","# 길이 분포 출력\n","text_len = [len(s) for s in encoder_input]\n","summary_len = [len(s) for s in decoder_input]\n","\n","print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n","print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n","print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n","print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n","print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n","print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n","\n","plt.subplot(1,2,1)\n","plt.boxplot(summary_len)\n","plt.title('contents')\n","plt.subplot(1,2,2)\n","plt.boxplot(text_len)\n","plt.title('title')\n","plt.tight_layout()\n","plt.show()\n","\n","plt.title('contents')\n","plt.hist(summary_len, bins=40)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()\n","\n","plt.title('title')\n","plt.hist(text_len, bins=40)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIIUftk_V6dx","colab_type":"code","colab":{}},"source":["# 정수 인코딩\n","tokenizer_con = Tokenizer()\n","tokenizer_con.fit_on_texts(encoder_input)\n","encoder_input_s = tokenizer_con.texts_to_sequences(encoder_input)\n","\n","tokenizer_head = Tokenizer()\n","tokenizer_head.fit_on_texts(decoder_input)\n","tokenizer_head.fit_on_texts(decoder_output)\n","decoder_input_s = tokenizer_head.texts_to_sequences(decoder_input)\n","decoder_output_s = tokenizer_head.texts_to_sequences(decoder_output)\n","\n","# 패딩\n","encoder_input_pad = pad_sequences(encoder_input_s, padding=\"post\", maxlen=1000)\n","decoder_input_pad = pad_sequences(decoder_input_s, padding=\"post\", maxlen=25)\n","decoder_output_pad = pad_sequences(decoder_output_s, padding=\"post\",maxlen=25)\n","\n","print(encoder_input_pad.shape)\n","print(decoder_input_pad.shape)\n","\n","head_to_index = tokenizer_head.word_index\n","index_to_head = tokenizer_head.index_word\n","\n","\n","# suffle\n","mb_size = 256\n","input_rows = len(encoder_input)\n","\n","shuffle_map = np.arange(input_rows)#################################\n","np.random.shuffle(shuffle_map)\n","step_count = int(input_rows * 0.8) // mb_size\n","test_begin_idx = step_count * mb_size\n","\n","\n","\n","\n","# train, test 데이터 분리\n","\n","encoder_input_train = encoder_input_pad[shuffle_map[:test_begin_idx]]\n","decoder_input_train = decoder_input_pad[shuffle_map[:test_begin_idx]]\n","decoder_output_train = decoder_output_pad[shuffle_map[:test_begin_idx]]\n","\n","encoder_input_test = encoder_input_pad[shuffle_map[test_begin_idx:]]\n","decoder_input_test = decoder_input_pad[shuffle_map[test_begin_idx:]]\n","decoder_output_test = decoder_output_pad[shuffle_map[test_begin_idx:]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNZq0Mv63_s2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598749189676,"user_tz":-540,"elapsed":908,"user":{"displayName":"하얀토마토","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6vDBrxCTQgLfR3k4Ki87kEMHbAng403bLeTrH=s64","userId":"01056407583135415771"}},"outputId":"481e4ee5-561e-485b-b47c-c72e16f5e688"},"source":["type(encoder_input_pad)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"ETT8zWajd_av","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","embedding_dim = 128\n","hidden_size = 64\n","\n","# 인코더 모델 쌓기\n","encoder_inputs = Input(shape=(1000,))\n","# 인코더의 임베딩 층\n","encoder_embed = Embedding(len(tokenizer_con.word_index)+1, embedding_dim)(encoder_inputs)\n","# 패딩(0)에 해당하는 임베딩 벡터는 제외 -- masking\n","encoder_mask = Masking(mask_value=0)(encoder_embed)\n","\n","# encoder_outputs, h_state, c_state = LSTM(hidden_size, return_state=True, return_sequences=True)(encoder_mask)\n","# 인코더의 LSTM 1\n","encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True )\n","encoder_output1, state_h1, state_c1 = encoder_lstm1(encoder_mask) # h1,c1 은 사용 안함\n","\n","# 인코더의 LSTM 2\n","encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True)\n","encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) # h2,c2 은 사용 안함\n","\n","# 인코더의 LSTM 3\n","# return sequences = True 를 통해서 어텐션을 구할 때 필요한 전체 시점의 히든 상태값을 리턴하도록!\n","# 드롭아웃 사용 -- 과적합 방지\n","encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.2) \n","encoder_outputs, h_state, c_state = encoder_lstm3(encoder_output2)\n","\n","\n","\n","\n","# 디코더 모델 쌓기\n","decoder_inputs = Input(shape=(25,))\n","decoder_embed = Embedding(len(tokenizer_head.word_index)+1, embedding_dim)(decoder_inputs)\n","decoder_mask = Masking(mask_value=0)(decoder_embed)\n","decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n","decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n","\n","\n","\n","\n","from attention import AttentionLayer\n","\n","# 어텐션 레이어 객체 생성\n","attn_layer = AttentionLayer()\n","# attn_out는 어텐션 밸류 (가중치가 보정된 인코더의 은닉 상태값의 합), attn_states는 가중치 \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","# 디코더의 히든상태랑 어텐션 밸류를 결합해서 새로운 출력 벡터 구함\n","decoder_concat_input = Concatenate()([decoder_outputs, attn_out])\n","\n","decoder_dense = Dense(len(tokenizer_head.word_index)+1, activation='softmax')\n","decoder_softmax_outputs = decoder_dense(decoder_concat_input)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNuTJE8blpAs","colab_type":"code","colab":{}},"source":["# # LSTM 한층만 사용 -- 속도..\n","\n","# from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Concatenate\n","# from tensorflow.keras.models import Model\n","# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","# embedding_dim = 128\n","# hidden_size = 64\n","\n","# # 인코더 모델 쌓기\n","# encoder_inputs = Input(shape=(1000,))\n","# # 인코더의 임베딩 층\n","# encoder_embed = Embedding(len(tokenizer_con.word_index)+1, embedding_dim)(encoder_inputs)\n","# # 패딩(0)에 해당하는 임베딩 벡터는 제외 -- masking\n","# encoder_mask = Masking(mask_value=0)(encoder_embed)\n","# encoder_outputs, h_state, c_state = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)(encoder_mask)\n","\n","# # 디코더 모델 쌓기\n","# decoder_inputs = Input(shape=(20,))\n","# decoder_embed = Embedding(len(tokenizer_head.word_index)+1, embedding_dim)(decoder_inputs)\n","# decoder_mask = Masking(mask_value=0)(decoder_embed)\n","# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True,dropout=0.2, recurrent_dropout=0.1)\n","# decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n","\n","\n","\n","\n","# from attention import AttentionLayer\n","\n","# # 어텐션 레이어 객체 생성\n","# attn_layer = AttentionLayer()\n","# # attn_out는 어텐션 밸류 (가중치가 보정된 인코더의 은닉 상태값의 합), attn_states는 가중치 \n","# attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","# # 디코더의 히든상태랑 어텐션 밸류를 결합해서 새로운 출력 벡터 구함\n","# decoder_concat_input = Concatenate()([decoder_outputs, attn_out])\n","\n","# decoder_dense = Dense(len(tokenizer_head.word_index)+1, activation='softmax')\n","# decoder_softmax_outputs = decoder_dense(decoder_concat_input)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVgX4_Yus62d","colab_type":"code","colab":{}},"source":["cp = ModelCheckpoint(filepath ='/content/drive/My Drive/best_kkma_model.h5' ,monitor='val_loss', verbose=1, save_best_only=True)\n","es = EarlyStopping(monitor='val_loss', patience=30)\n","\n","# 모델 훈련\n","model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = mb_size, epochs = 200, callbacks=[cp,es])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_c_u0-xztMB","colab_type":"code","colab":{}},"source":["model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVQZstyJE8Bs","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","# 모델 저장\n","model.save('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/kkma_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXvvU6TPjXYk","colab_type":"code","colab":{}},"source":["# 어텐션 계산을 위해 출력으로 encoder_outputs 까지!\n","encoder_model = Model(encoder_inputs, [encoder_outputs, h_state, c_state])\n","\n","\n","encoder_h_state = Input(shape=(hidden_size,))\n","encoder_c_state = Input(shape=(hidden_size,))\n","\n","pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n","\n","# 어텐션\n","# 1000 시점 (단어, 패딩) 의 수, hidden_size는 히든 스테이트의 차원\n","pd_encoder_outputs = Input(shape=(1000, hidden_size))\n","pd_attn_out, pd_attn_states = attn_layer([pd_encoder_outputs, pd_decoder_outputs])\n","pd_decoder_concat = Concatenate()([pd_decoder_outputs, pd_attn_out])\n","\n","pd_decoder_softmax_outputs = decoder_dense(pd_decoder_concat)\n","\n","# 어텐션은 디코더 모델 안에서 사용하는거기 때문에, 인풋으로 encoder outputs 까지 넣어준다!\n","\n","decoder_model = Model([decoder_inputs, pd_encoder_outputs, encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs, pd_h_state, pd_c_state])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uO5KQ3KBE9Am","colab_type":"code","colab":{}},"source":["# 인코더 디코더 모델 저장\n","encoder_model.save('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/kkma_encoder_model.h5')\n","decoder_model.save('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/kkma_decoder_model.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lufFWbMrjBh","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","\n","plt.plot(history.history['loss'], label='train')\n","plt.plot(history.history['val_loss'], label='test')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","plt.plot(history.history['acc'], label='train_acc')\n","plt.plot(history.history['val_acc'], label='test_acc')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N41DXZGE5DTH","colab_type":"text"},"source":["# 모델불러오기"]},{"cell_type":"code","metadata":{"id":"JIGbauIi5KPW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1598749589688,"user_tz":-540,"elapsed":19567,"user":{"displayName":"하얀토마토","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6vDBrxCTQgLfR3k4Ki87kEMHbAng403bLeTrH=s64","userId":"01056407583135415771"}},"outputId":"09d8eb65-a6d6-4884-fbaa-d94caf317f0c"},"source":["encoder_model = keras.models.load_model('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/kkma_encoder_model.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"srP_daey6N6R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1598750007954,"user_tz":-540,"elapsed":5113,"user":{"displayName":"하얀토마토","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6vDBrxCTQgLfR3k4Ki87kEMHbAng403bLeTrH=s64","userId":"01056407583135415771"}},"outputId":"4efba58b-a3d5-422d-b7f3-ac9c2bcac6b9"},"source":["from attention import AttentionLayer\n","decoder_model = keras.models.load_model('/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/kkma_decoder_model.h5', custom_objects={'AttentionLayer': AttentionLayer})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KT_UadxoeS4k","colab_type":"text"},"source":["# 내용입력부분"]},{"cell_type":"code","metadata":{"id":"qn4w9cz8eUwU","colab_type":"code","colab":{}},"source":["# 전체의 10퍼센트 정도의 데이터를 예측\n","# suffle\n","mb_size = 256\n","input_rows = len(encoder_input)\n","\n","shuff = np.arange(input_rows)#################################\n","np.random.shuffle(shuff)\n","step_count = int(input_rows * 0.9) // mb_size\n","test_begin_idx = step_count * mb_size\n","\n","# array로 type변경\n","cont = news.content[:16500]\n","cont = cont.to_numpy()\n","\n","\n","\n","predicted_title = []\n","\n","for inp in cont[shuff[test_begin_idx:]]:\n","    input_stc = inp\n","    token_stc = kkma.morphs(input_stc)\n","    encode_stc = tokenizer_con.texts_to_sequences([token_stc])\n","    pad_stc = pad_sequences(encode_stc, maxlen=1000, padding=\"post\")\n","\n","    # 출력이 3가지 (전체 시점의 히든 상태값, 마지막 시점의 히든/셀 상태 값) 가 나온다\n","    en_out, en_hidden, en_cell = encoder_model.predict(pad_stc)\n","\n","    predicted_seq = np.zeros((1,1))\n","    predicted_seq[0, 0] = head_to_index['<start>']\n","\n","    decoded_stc = []\n","\n","    while True:\n","        # 여기서 인풋으로 en_out 도 같이 넣어준다!\n","        output_words, h, c = decoder_model.predict([predicted_seq, en_out, en_hidden, en_cell])\n","        # print(index_to_head)\n","        \n","        predicted_word = index_to_head[np.argmax(output_words[0,0])]\n","        # print(predicted_word)\n","        \n","        if predicted_word == '<end>':\n","            break\n","        \n","        decoded_stc.append(predicted_word)\n","\n","        predicted_seq = np.zeros((1,1))\n","        predicted_seq[0, 0] = np.argmax(output_words[0, 0])\n","\n","        en_hidden = h\n","        en_cell = c\n","\n","    result = ' '.join(decoded_stc)\n","    predicted_title.append(result)\n","    print(result)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utyc4QRSi1ei","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598760382704,"user_tz":-540,"elapsed":879,"user":{"displayName":"하얀토마토","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6vDBrxCTQgLfR3k4Ki87kEMHbAng403bLeTrH=s64","userId":"01056407583135415771"}},"outputId":"5515e7c6-5a5b-43ce-9301-d092ca1339b0"},"source":["len(predicted_title)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5726"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"_8e4bDG5AKEP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598760948510,"user_tz":-540,"elapsed":839,"user":{"displayName":"하얀토마토","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6vDBrxCTQgLfR3k4Ki87kEMHbAng403bLeTrH=s64","userId":"01056407583135415771"}},"outputId":"656c1639-5d96-4965-df95-f9f2053a70a6"},"source":["label_title = []\n","head = news.headline[:16500]\n","head = head.to_numpy()\n","i = 0\n","for inp in head[shuff[test_begin_idx:]]:\n","    label_title.append(inp)\n","    i += 1\n","    if i == 5726:\n","        break\n","\n","contents = []\n","i = 0\n","for inp in cont[shuff[test_begin_idx:]]:\n","    contents.append(inp)\n","    i += 1\n","    if i == 5726:\n","        break\n","\n","\n","print(len(label_title))\n","print(len(contents))\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5726\n","5726\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IkwyOsYri5Sk","colab_type":"code","colab":{}},"source":["title = {'labeled_title' : label_title, 'predicted_title': predicted_title, 'content' : contents}\n","title_df = pd.DataFrame(title)\n","title_df\n","title_df.to_csv(\"/content/drive/My Drive/인공지능 학습관련/자연어 프로젝트/labeled_predicted_title_kkma.csv\", mode='w', encoding='utf-8-sig')\n"],"execution_count":null,"outputs":[]}]}